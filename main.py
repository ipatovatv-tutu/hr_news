print("–§–ê–ô–õ main.py –ó–ê–ü–£–°–¢–ò–õ–°–Ø")

import warnings
warnings.filterwarnings("ignore", category=UserWarning, module="urllib3")

import re
import json
import os
import time
import threading
import feedparser
import requests
from datetime import datetime
from urllib.parse import parse_qs, urlparse, unquote
from openai import OpenAI
import asyncio
from telethon import TelegramClient
import warnings

# =====================
# IGNORE URLLIB3 WARNINGS
# =====================
warnings.filterwarnings("ignore", category=UserWarning, module="urllib3")

# =====================
# TELEGRAM BOT
# =====================
# –î–ª—è GitHub Actions –∑–∞–¥–∞–π —Å–µ–∫—Ä–µ—Ç—ã: TELEGRAM_TOKEN, CHAT_ID, OPENAI_API_KEY
TELEGRAM_TOKEN = os.environ.get("TELEGRAM_TOKEN") or "8519637323:AAHgqQfKuk8Hvw1kmbFe4Ck_stEm4xMC4Zo"
CHAT_ID = os.environ.get("CHAT_ID") or "281610747"

# –†–∞—Å–ø–∏—Å–∞–Ω–∏–µ: –ø–æ–Ω–µ–¥–µ–ª—å–Ω–∏–∫ –∏ —á–µ—Ç–≤–µ—Ä–≥ –≤ 09:00
DIGEST_WEEKDAYS = (0, 3)  # 0 = Monday, 3 = Thursday
DIGEST_TIME = "09:00"  # –ª–æ–∫–∞–ª—å–Ω–æ–µ –≤—Ä–µ–º—è

# –£–∂–µ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–µ —Å—Å—ã–ª–∫–∏ ‚Äî —á—Ç–æ–±—ã –Ω–æ–≤–æ—Å—Ç–∏ –Ω–µ –ø–æ–≤—Ç–æ—Ä—è–ª–∏—Å—å (—Ñ–∞–π–ª —Ä—è–¥–æ–º —Å–æ —Å–∫—Ä–∏–ø—Ç–æ–º)
_SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
SENT_ARTICLES_FILE = os.path.join(_SCRIPT_DIR, "sent_articles.json")
MAX_SENT_ARTICLES = 500


def load_sent_articles() -> set:
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –º–Ω–æ–∂–µ—Å—Ç–≤–æ —É–∂–µ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã—Ö URL –∏–∑ JSON."""
    if not os.path.isfile(SENT_ARTICLES_FILE):
        return set()
    try:
        with open(SENT_ARTICLES_FILE, "r", encoding="utf-8") as f:
            data = json.load(f)
        links = data.get("links", [])
        return set(links[-MAX_SENT_ARTICLES:])
    except Exception:
        return set()


def save_sent_articles(links: list):
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Å–ø–∏—Å–æ–∫ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã—Ö URL (—Ö—Ä–∞–Ω–∏–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ MAX_SENT_ARTICLES)."""
    try:
        with open(SENT_ARTICLES_FILE, "r", encoding="utf-8") as f:
            data = json.load(f)
        existing = data.get("links", [])
    except (FileNotFoundError, json.JSONDecodeError):
        existing = []
    existing = (existing + links)[-MAX_SENT_ARTICLES:]
    with open(SENT_ARTICLES_FILE, "w", encoding="utf-8") as f:
        json.dump({"links": existing, "updated": datetime.now().isoformat()}, f, ensure_ascii=False)
    print("–°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã—Ö —Å—Å—ã–ª–æ–∫:", len(existing))
    return


def extract_article_links(text: str) -> list:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∏–∑ —Ç–µ–∫—Å—Ç–∞ –¥–∞–π–¥–∂–µ—Å—Ç–∞ —Å—Å—ã–ª–∫–∏ –Ω–∞ —Å—Ç–∞—Ç—å–∏ (vc.ru, career.habr, habr.com)."""
    if not text:
        return []
    pattern = r"https?://(?:vc\.ru/hr/\d[^\s\)\]]*|career\.habr\.com/[^\s\)\]]*|habr\.com/ru/[^\s\)\]]*)"
    return list(dict.fromkeys(re.findall(pattern, text)))


# –õ–∏–º–∏—Ç Telegram ‚Äî 4096 —Å–∏–º–≤–æ–ª–æ–≤ –Ω–∞ —Å–æ–æ–±—â–µ–Ω–∏–µ; –æ—Å—Ç–∞–≤–ª—è–µ–º –∑–∞–ø–∞—Å –ø–æ–¥ HTML
TELEGRAM_MAX_MESSAGE_LENGTH = 4000


def _split_message_for_telegram(text: str, max_len: int = TELEGRAM_MAX_MESSAGE_LENGTH) -> list:
    """–†–∞–∑–±–∏–≤–∞–µ—Ç –¥–ª–∏–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –Ω–∞ —á–∞—Å—Ç–∏ –ø–æ max_len, —Ä–µ–∂–µ—Ç –ø–æ –≥—Ä–∞–Ω–∏—Ü–∞–º –∞–±–∑–∞—Ü–µ–≤ (\\n\\n)."""
    if not text or len(text) <= max_len:
        return [text] if text else []
    chunks = []
    rest = text
    while rest:
        if len(rest) <= max_len:
            chunks.append(rest)
            break
        part = rest[:max_len]
        # –ò—â–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π –¥–≤–æ–π–Ω–æ–π –ø–µ—Ä–µ–Ω–æ—Å, —á—Ç–æ–±—ã –Ω–µ —Ä–µ–∑–∞—Ç—å –ø–æ—Å–µ—Ä–µ–¥–∏–Ω–µ –Ω–æ–≤–æ—Å—Ç–∏
        last_para = part.rfind("\n\n")
        if last_para > max_len // 2:
            part = part[:last_para + 2].rstrip()
            rest = rest[len(part):].lstrip()
        else:
            # –†–µ–∂–µ–º –ø–æ –æ–¥–∏–Ω–æ—á–Ω–æ–º—É –ø–µ—Ä–µ–Ω–æ—Å—É
            last_n = part.rfind("\n")
            if last_n > max_len // 2:
                part = part[:last_n + 1].rstrip()
                rest = rest[len(part):].lstrip()
            else:
                part = part.rstrip()
                rest = rest[len(part):].lstrip()
        chunks.append(part)
    return chunks


def send_to_telegram(text, chat_id=None):
    """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏–µ –≤ Telegram. –ï—Å–ª–∏ —Ç–µ–∫—Å—Ç –¥–ª–∏–Ω–Ω–µ–µ –ª–∏–º–∏—Ç–∞ ‚Äî —à–ª—ë—Ç –Ω–µ—Å–∫–æ–ª—å–∫–∏–º–∏ —Å–æ–æ–±—â–µ–Ω–∏—è–º–∏."""
    if not text or not text.strip():
        return
    chat_id = chat_id or CHAT_ID
    for chunk in _split_message_for_telegram(text):
        url = f"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendMessage"
        try:
            r = requests.post(
                url,
                json={
                    "chat_id": chat_id,
                    "text": chunk,
                    "parse_mode": "HTML",
                    "disable_web_page_preview": True
                },
                timeout=30
            )
            if r.status_code != 200 or not r.json().get("ok"):
                print("Telegram –æ—à–∏–±–∫–∞:", r.status_code, r.text[:500])
        except Exception as e:
            print("Telegram –æ—Ç–ø—Ä–∞–≤–∫–∞ –æ—à–∏–±–∫–∞:", e)


def clean_digest_block(text: str) -> str:
    """
    –£–±–∏—Ä–∞–µ—Ç –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã –∏–∑ –æ—Ç–≤–µ—Ç–∞ –ò–ò: –æ–±—ë—Ä—Ç–∫–∏ ```html –∏ ```, –ø—Ä–µ–≤—Ä–∞—â–∞–µ—Ç
    ¬´–ò—Å—Ç–æ—á–Ω–∏–∫: label (URL)¬ª –≤ –∫–ª–∏–∫–∞–±–µ–ª—å–Ω—ã–µ —Å—Å—ã–ª–∫–∏. –ó–∞–º–µ–Ω—è–µ—Ç placeholder 123456-slug –Ω–∞ —Å—Å—ã–ª–∫—É –Ω–∞ —Ä–∞–∑–¥–µ–ª.
    """
    if not text or not text.strip():
        return text
    s = text.strip()
    # –£–±–∏—Ä–∞–µ–º –æ—Ç–∫—Ä—ã–≤–∞—é—â–∏–π ```html –∏–ª–∏ ``` –≤ –Ω–∞—á–∞–ª–µ
    s = re.sub(r"^\s*```html?\s*\n?", "", s, flags=re.I)
    # –£–±–∏—Ä–∞–µ–º –∑–∞–∫—Ä—ã–≤–∞—é—â–∏–π ``` –≤ –∫–æ–Ω—Ü–µ
    s = re.sub(r"\n?\s*```\s*$", "", s)
    s = s.strip()
    # Placeholder –æ—Ç –ò–ò (123456-slug) –≤–µ–¥—ë—Ç –Ω–µ —Ç—É–¥–∞ ‚Äî –∑–∞–º–µ–Ω—è–µ–º –Ω–∞ —Ä–∞–∑–¥–µ–ª
    s = re.sub(r'href="https://vc\.ru/hr/123456-slug"', 'href="https://vc.ru/hr"', s, flags=re.I)
    # ¬´–ò—Å—Ç–æ—á–Ω–∏–∫: label (https://...)¬ª ‚Üí <a href="URL">–ò—Å—Ç–æ—á–Ω–∏–∫: label</a>
    def _link(m):
        label = m.group(1).strip()
        url = m.group(2)
        if "123456-slug" in url:
            url = "https://vc.ru/hr" if "vc.ru" in url else "https://career.habr.com/journal"
        return f'<a href="{url}">–ò—Å—Ç–æ—á–Ω–∏–∫: {label}</a>'
    s = re.sub(
        r"–ò—Å—Ç–æ—á–Ω–∏–∫: ([^\n]+?) \((https?://[^)\s]+)\)",
        _link,
        s,
    )
    # –í –≥–æ—Ç–æ–≤–æ–º —Ç–µ–∫—Å—Ç–µ –∑–∞–º–µ–Ω—è–µ–º –æ—Å—Ç–∞–≤—à–∏–µ—Å—è api.vc.ru/redirect –Ω–∞ —Ä–µ–∞–ª—å–Ω—ã–π URL
    s = re.sub(r'href="(https?://api\.vc\.ru/[^"]+)"', lambda m: f'href="{_normalize_vc_redirect_link(m.group(1))}"', s)
    return s

# =====================
# OPENAI
# =====================
OPENAI_API_KEY = os.environ.get("OPENAI_API_KEY")
client = OpenAI(api_key=OPENAI_API_KEY)

def hr_insight_ai(title, summary):
    prompt = f"""
–¢—ã ‚Äî HR-—Å—Ç—Ä–∞—Ç–µ–≥ –¥–ª—è –∫—Ä—É–ø–Ω–æ–π tech-–∫–æ–º–ø–∞–Ω–∏–∏.

–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –Ω–æ–≤–æ—Å—Ç—å –∏ –æ—Ç–≤–µ—Ç—å —Å—Ç—Ä–æ–≥–æ –≤ —Ç–∞–∫–æ–º —Ñ–æ—Ä–º–∞—Ç–µ:

HR-—Å–∏–≥–Ω–∞–ª: –¥–∞ / –Ω–µ—Ç
–ö–∞—Ç–µ–≥–æ—Ä–∏—è: —Ä—ã–Ω–æ–∫ —Ç—Ä—É–¥–∞ / –∫–æ–º–ø–µ–Ω—Å–∞—Ü–∏–∏ / –∫—É–ª—å—Ç—É—Ä–∞ / –º–µ–Ω–µ–¥–∂–º–µ–Ω—Ç / –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏—è / —Ä–µ–≥—É–ª—è—Ç–æ—Ä–∏–∫–∞ / –¥—Ä—É–≥–æ–µ
–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π –¥–ª—è HR: 1‚Äì2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –ø—Ä–æ—Å—Ç—ã–º —è–∑—ã–∫–æ–º

–ù–æ–≤–æ—Å—Ç—å:
{title}

–û–ø–∏—Å–∞–Ω–∏–µ:
{summary}
"""
    try:
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "–¢—ã –æ–ø—ã—Ç–Ω—ã–π HR-–¥–∏—Ä–µ–∫—Ç–æ—Ä –∏ —Å—Ç—Ä–∞—Ç–µ–≥."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.3,
        )
        return response.choices[0].message.content.strip()
    except Exception:
        return "–ú–∞—Ç–µ—Ä–∏–∞–ª –ø–æ —Ç–µ–º–µ HR –∏ –∫–∞—Ä—å–µ—Ä—ã."

# =====================
# RSS SOURCES
# =====================
SOURCES = [
    "https://www.rbc.ru/rss",
    "https://www.vedomosti.ru/rss",
    "https://www.forbes.ru/newrss",
    "https://www.kommersant.ru/RSS/main.xml",
    "https://rss.nytimes.com/services/xml/rss/nyt/Business.xml",
]

# vc.ru ‚Äî Playwright —Å–æ–±–∏—Ä–∞–µ—Ç —Å—Å—ã–ª–∫–∏ –∏ –∑–∞–≥–æ–ª–æ–≤–∫–∏, –ò–ò —Ñ–æ—Ä–º–∏—Ä—É–µ—Ç –¥–∞–π–¥–∂–µ—Å—Ç –∑–∞ –Ω–µ–¥–µ–ª—é –ø–æ HR
VC_CHANNEL_URL = "https://vc.ru/hr"
VC_CHANNEL_MAX = 20   # —Å–æ–±–∏—Ä–∞–µ–º —Å—Ç–∞—Ç–µ–π —Å –ª–µ–Ω—Ç—ã, –ò–ò –≤—ã–±–µ—Ä–µ—Ç –¥–æ 10 —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –∑–∞ –Ω–µ–¥–µ–ª—é
VC_DISCOVERY_QUERY = "HR"
VC_DISCOVERY_MAX = 10
# –ï—Å–ª–∏ False ‚Äî –≤—Å–µ —Å—Ç–∞—Ç—å–∏ —Å vc.ru –ø–æ–ø–∞–¥–∞—é—Ç –≤ –¥–∞–π–¥–∂–µ—Å—Ç –±–µ–∑ –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø–æ HR_KEYWORDS (—É–¥–æ–±–Ω–æ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏).
VC_FILTER_BY_HR_KEYWORDS = False

# –•–∞–±—Ä –ö–∞—Ä—å–µ—Ä–∞ ‚Äî –∂—É—Ä–Ω–∞–ª (–∫–∞—Ä—å–µ—Ä–∞, HR, –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ IT)
HABR_JOURNAL_URL = "https://career.habr.com/journal"

# –ö—Ä–∏—Ç–µ—Ä–∏–∏ –æ—Ç–±–æ—Ä–∞ –¥–ª—è HR-–¥–∞–π–¥–∂–µ—Å—Ç–∞: —á—Ç–æ –≤–∫–ª—é—á–∞—Ç—å –∏ —á—Ç–æ –æ—Ç—Å–µ–∫–∞—Ç—å (–∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≤ –ø—Ä–æ–º–ø—Ç–∞—Ö –ò–ò)
HR_DIGEST_CRITERIA = """
–¶–µ–ª—å –¥–∞–π–¥–∂–µ—Å—Ç–∞ ‚Äî –ø–æ–º–æ—á—å HR-—Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç—É –æ—Å—Ç–∞–≤–∞—Ç—å—Å—è –≤ –∫—É—Ä—Å–µ —Ç—Ä–µ–Ω–¥–æ–≤, –∏–∑–º–µ–Ω–µ–Ω–∏–π –≤ –ø—Ä–æ—Ñ–µ—Å—Å–∏–∏ –∏ —Ä—ã–Ω–∫–µ —Ç—Ä—É–¥–∞, —Ä–∞–∑–≤–∏–≤–∞—Ç—å—Å—è –≤ –∫–æ–º–º—É–Ω–∏–∫–∞—Ü–∏—è—Ö, –ò–ò, –ø–æ—Å—Ç–∞–Ω–æ–≤–∫–µ —Ü–µ–ª–µ–π –∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–∏ –ª—é–¥—å–º–∏.

–í–ö–õ–Æ–ß–ê–ô:
- HR-—Ç—Ä–µ–Ω–¥—ã, –∏–∑–º–µ–Ω–µ–Ω–∏—è –≤ –ø—Ä–æ—Ñ–µ—Å—Å–∏–∏ HR, —Ä—ã–Ω–æ–∫ —Ç—Ä—É–¥–∞ (–Ω–∞–π–º, —É–≤–æ–ª—å–Ω–µ–Ω–∏—è, –∑–∞—Ä–ø–ª–∞—Ç—ã, —Å–ø—Ä–æ—Å –Ω–∞ —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç–æ–≤)
- –†–µ–∫—Ä—É—Ç–∏–Ω–≥, –æ—Ç–±–æ—Ä, –∏–Ω—Ç–µ—Ä–≤—å—é, employer brand
- –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ª—é–¥—å–º–∏, –∫–æ–º–∞–Ω–¥—ã, –ª–∏–¥–µ—Ä—Å—Ç–≤–æ, –æ–±—Ä–∞—Ç–Ω–∞—è —Å–≤—è–∑—å, —Å–ª–æ–∂–Ω—ã–µ —Ä–∞–∑–≥–æ–≤–æ—Ä—ã
- –ò–ò –≤ HR: –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏—è –Ω–∞–π–º–∞, HR-–∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã, –Ω–µ–π—Ä–æ—Å–µ—Ç–∏ –≤ —Ä–µ–∫—Ä—É—Ç–∏–Ω–≥–µ –∏ –æ—Ü–µ–Ω–∫–µ
- –ü–æ—Å—Ç–∞–Ω–æ–≤–∫–∞ —Ü–µ–ª–µ–π (OKR, KPI), –æ—Ü–µ–Ω–∫–∞ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏, performance management
- –û–±—É—á–µ–Ω–∏–µ –∏ —Ä–∞–∑–≤–∏—Ç–∏–µ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤ (L&D), –∞–¥–∞–ø—Ç–∞—Ü–∏—è, –æ–Ω–±–æ—Ä–¥–∏–Ω–≥, —É–¥–µ—Ä–∂–∞–Ω–∏–µ
- –ö–æ–º–ø–µ–Ω—Å–∞—Ü–∏–∏, –º–æ—Ç–∏–≤–∞—Ü–∏—è, –±–µ–Ω–µ—Ñ–∏—Ç—ã, –∫—É–ª—å—Ç—É—Ä–∞, –≤–æ–≤–ª–µ—á—ë–Ω–Ω–æ—Å—Ç—å
- –ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è –ø–æ —Ä—ã–Ω–∫—É —Ç—Ä—É–¥–∞, –æ–ø—Ä–æ—Å—ã —Ä–∞–±–æ—Ç–æ–¥–∞—Ç–µ–ª–µ–π –∏ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤, —Ä–µ–≥—É–ª—è—Ç–æ—Ä–∏–∫–∞ –¥–ª—è HR

–ù–ï –í–ö–õ–Æ–ß–ê–ô:
- –ö–∞—Ä—å–µ—Ä–Ω—ã–µ –≥–∞–π–¥—ã –¥–ª—è –Ω–µ-HR —Ä–æ–ª–µ–π: ¬´–∫–∞—Ä—å–µ—Ä–∞ –≤ –º–∞—Ä–∫–µ—Ç–∏–Ω–≥–µ¬ª, ¬´–∫–∞–∫ —Å—Ç–∞—Ç—å —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–æ–º¬ª, ¬´–∫–∞—Ä—å–µ—Ä–∞ –±—ç–∫–µ–Ω–¥–µ—Ä–∞/—Ç–µ—Å—Ç–∏—Ä–æ–≤—â–∏–∫–∞/–¥–∏–∑–∞–π–Ω–µ—Ä–∞¬ª ‚Äî –µ—Å–ª–∏ –º–∞—Ç–µ—Ä–∏–∞–ª –Ω–µ –ø—Ä–æ —Ä–∞–±–æ—Ç—É HR-—Ñ—É–Ω–∫—Ü–∏–∏
- –û–±—â–∏–µ —Å—Ç–∞—Ç—å–∏ ¬´–∫–∞–∫ –≤–æ–π—Ç–∏ –≤ IT¬ª –¥–ª—è –ø—Ä–æ–≥—Ä–∞–º–º–∏—Å—Ç–æ–≤ –±–µ–∑ –ø—Ä–∏–≤—è–∑–∫–∏ –∫ HR
- –£–∑–∫–∏–µ —Å–æ–≤–µ—Ç—ã –ø–æ –∫–∞—Ä—å–µ—Ä–µ –≤ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –Ω–µ-HR —Å–ø–µ—Ü–∏–∞–ª—å–Ω–æ—Å—Ç–∏ (–µ—Å–ª–∏ –Ω–µ –ø—Ä–æ —Ç–æ, –∫–∞–∫ HR —Å —ç—Ç–∏–º —Ä–∞–±–æ—Ç–∞—Ç—å)
"""

# –õ–∏–º–∏—Ç—ã –¥–∞–π–¥–∂–µ—Å—Ç–∞ (—Ä–∞–Ω—å—à–µ –±—ã–ª–æ 7 –ø–æ RSS ‚Äî –∏–∑-–∑–∞ —ç—Ç–æ–≥–æ –Ω–æ–≤–æ—Å—Ç–µ–π –ø–æ—á—Ç–∏ –Ω–µ –±—ã–ª–æ)
MAX_RSS_ITEMS = 15          # –º–∞–∫—Å. –Ω–æ–≤–æ—Å—Ç–µ–π –∏–∑ –≤—Å–µ—Ö RSS-–∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
MAX_VC_AI_ITEMS = 10        # –º–∞–∫—Å. —Å—Ç–∞—Ç–µ–π –≤ –¥–∞–π–¥–∂–µ—Å—Ç–µ vc.ru –æ—Ç –ò–ò
HR_KEYWORDS = [
    "hr", "employee", "job", "layoff", "hiring",
    "—Å–æ—Ç—Ä—É–¥–Ω–∏–∫", "–ø–µ—Ä—Å–æ–Ω–∞–ª", "—É–≤–æ–ª—å–Ω", "–Ω–∞–π–º",
    "–∫–æ–º–∞–Ω–¥–∞", "–º–æ—Ç–∏–≤–∞—Ü", "–∫—É–ª—å—Ç—É—Ä–∞", "–º–µ–Ω–µ–¥–∂–µ—Ä",
    "—Ä—ã–Ω–æ–∫ —Ç—Ä—É–¥–∞", "–∫–∞–¥—Ä—ã", "recruit"
]
# –ï—Å–ª–∏ True ‚Äî –≤ RSS –ø–æ–ø–∞–¥–∞—é—Ç —Ç–æ–ª—å–∫–æ —Å—Ç–∞—Ç—å–∏, –≥–¥–µ –µ—Å—Ç—å —Ö–æ—Ç—è –±—ã –æ–¥–Ω–æ —Å–ª–æ–≤–æ –∏–∑ HR_KEYWORDS.
# –ï—Å–ª–∏ –¥–∞–π–¥–∂–µ—Å—Ç –ø—É—Å—Ç–æ–π ‚Äî –ø–æ—Å—Ç–∞–≤—å False: —Ç–æ–≥–¥–∞ –≤ –¥–∞–π–¥–∂–µ—Å—Ç –ø–æ–ø–∞–¥—É—Ç –≤—Å–µ –Ω–æ–≤–æ—Å—Ç–∏ –∏–∑ RSS (–¥–æ MAX_RSS_ITEMS).
RSS_FILTER_BY_HR_KEYWORDS = False


def collect_rss_news():
    block = ""
    used_titles = set()
    total_seen = 0
    skipped_hr_filter = 0

    for source in SOURCES:
        feed = feedparser.parse(source)
        for entry in feed.entries:
            title = entry.title
            summary = entry.summary if hasattr(entry, "summary") else ""
            link = entry.get("link", "")
            text = (title + " " + summary).lower()
            total_seen += 1

            if RSS_FILTER_BY_HR_KEYWORDS and not any(word in text for word in HR_KEYWORDS):
                skipped_hr_filter += 1
                continue
            if title in used_titles:
                continue

            analysis = hr_insight_ai(title, summary)

            # –≤—Ä–µ–º–µ–Ω–Ω–æ –ù–ï –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤—ã–≤–∞–µ–º "HR-—Å–∏–≥–Ω–∞–ª: –Ω–µ—Ç"
            # if "hr-—Å–∏–≥–Ω–∞–ª: –Ω–µ—Ç" in analysis.lower():
            #     continue

            used_titles.add(title)
            source_line = f'  <a href="{link}">–ò—Å—Ç–æ—á–Ω–∏–∫</a>\n' if link else ""
            block += (
                f"‚Ä¢ {title}\n"
                f"  <i>{analysis}</i>\n"
                f"{source_line}\n"
            )

            if len(used_titles) >= MAX_RSS_ITEMS:
                print("RSS: –≤—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π", total_seen, "| –æ—Ç–±—Ä–æ—à–µ–Ω–æ –ø–æ HR-—Ñ–∏–ª—å—Ç—Ä—É:", skipped_hr_filter, "| –≤ –¥–∞–π–¥–∂–µ—Å—Ç:", len(used_titles))
                return block, used_titles

    print("RSS: –≤—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π", total_seen, "| –æ—Ç–±—Ä–æ—à–µ–Ω–æ –ø–æ HR-—Ñ–∏–ª—å—Ç—Ä—É:", skipped_hr_filter, "| –≤ –¥–∞–π–¥–∂–µ—Å—Ç:", len(used_titles))
    return block, used_titles


def _normalize_vc_redirect_link(link: str) -> str:
    """–ü—Ä–µ–≤—Ä–∞—â–∞–µ—Ç api.vc.ru/redirect?to=... –≤ —Ä–µ–∞–ª—å–Ω—ã–π URL (–¥–µ–∫–æ–¥–∏—Ä—É–µ—Ç to=)."""
    if not link or "api.vc.ru" not in link or "redirect" not in link:
        return link
    try:
        parsed = urlparse(link)
        qs = parse_qs(parsed.query)
        to_list = qs.get("to") or []
        to = (to_list[0] if to_list else None)
        if to:
            return unquote(to)
    except Exception:
        pass
    return link


def _add_vc_articles_to_block(articles, used_titles, max_items, source_label="vc.ru"):
    """–û–±—â–∞—è –ª–æ–≥–∏–∫–∞: –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ —Ñ–∏–ª—å—Ç—Ä –ø–æ HR_KEYWORDS, –ò–ò, –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ –≤ block. –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Å—Ç–∞—Ç—å–∏ —Å –∫–æ—Ä–æ—Ç–∫–∏–º/–º—É—Å–æ—Ä–Ω—ã–º –∑–∞–≥–æ–ª–æ–≤–∫–æ–º."""
    block = ""
    added = 0
    for item in articles:
        if added >= max_items:
            break
        title = (item.get("title", "") or "").strip()
        link = _normalize_vc_redirect_link(item.get("link", "") or "")
        snippet = item.get("snippet", title)
        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Ç–æ–ª—å–∫–æ —è–≤–Ω—ã–π –º—É—Å–æ—Ä (–æ—á–µ–Ω—å –∫–æ—Ä–æ—Ç–∫–∏–µ –æ–±—Ä–µ–∑–∫–∏), –∏–Ω–∞—á–µ –≤ –¥–∞–π–¥–∂–µ—Å—Ç–µ –Ω–∏—á–µ–≥–æ –Ω–µ –æ—Å—Ç–∞—ë—Ç—Å—è
        if not title or len(title) < 10 or title in used_titles:
            continue
        if VC_FILTER_BY_HR_KEYWORDS:
            text = (title + " " + snippet).lower()
            if not any(word in text for word in HR_KEYWORDS):
                continue

        analysis = hr_insight_ai(title, snippet)
        used_titles.add(title)
        source_line = f'  <a href="{link}">–ò—Å—Ç–æ—á–Ω–∏–∫: {source_label}</a>\n' if link else ""
        block += (
            f"‚Ä¢ {title}\n"
            f"  <i>{analysis}</i>\n"
            f"{source_line}\n"
        )
        added += 1
    return block, used_titles, added


def hr_digest_from_vc_articles(articles: list) -> str:
    """
    –ò–ò –ø–æ–ª—É—á–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —Å—Ç–∞—Ç–µ–π —Å vc.ru (–∑–∞–≥–æ–ª–æ–≤–æ–∫ + —Å—Å—ã–ª–∫–∞ + —Å–Ω–∏–ø–ø–µ—Ç).
    –í—ã–±–∏—Ä–∞–µ—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –¥–ª—è HR –∑–∞ –ø–æ—Å–ª–µ–¥–Ω—é—é –Ω–µ–¥–µ–ª—é, –ø–∏—à–µ—Ç –∫–æ—Ä–æ—Ç–∫–∏–π –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π –ø–æ –∫–∞–∂–¥–æ–π,
    –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –≥–æ—Ç–æ–≤—ã–π HTML-–±–ª–æ–∫ –¥–ª—è Telegram. –°—Å—ã–ª–∫–∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–µ, —á—Ç–æ –ø–µ—Ä–µ–¥–∞–ª–∏ ‚Äî –Ω–µ –≤—ã–¥—É–º—ã–≤–∞–µ—Ç.
    """
    if not articles:
        return ""
    # –°—Ç—Ä–æ–∏–º —Å–ø–∏—Å–æ–∫ –¥–ª—è –ø—Ä–æ–º–ø—Ç–∞: –Ω–æ–º–µ—Ä, –∑–∞–≥–æ–ª–æ–≤–æ–∫, —Å—Å—ã–ª–∫–∞, —Å–Ω–∏–ø–ø–µ—Ç
    lines = []
    for i, a in enumerate(articles[:30], 1):  # –Ω–µ –±–æ–ª—å—à–µ 30 –≤ –ø—Ä–æ–º–ø—Ç
        title = (a.get("title") or "").strip()
        link = (a.get("link") or "").strip()
        snippet = (a.get("snippet") or title or "")[:500]
        if not title:
            continue
        lines.append(f"{i}. {title}\n   –°—Å—ã–ª–∫–∞: {link}\n   –¢–µ–∫—Å—Ç: {snippet}")
    text_list = "\n\n".join(lines)
    if not text_list:
        return ""

    prompt = f"""–ù–∏–∂–µ —Å–ø–∏—Å–æ–∫ —Å—Ç–∞—Ç–µ–π —Å vc.ru (—Ä–∞–∑–¥–µ–ª HR/–ö–∞—Ä—å–µ—Ä–∞). –õ–µ–Ω—Ç–∞ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Å–≤–µ–∂–∏–µ –ø–µ—Ä–≤—ã–º–∏ ‚Äî —Å—á–∏—Ç–∞–π, —á—Ç–æ —ç—Ç–æ –º–∞—Ç–µ—Ä–∏–∞–ª—ã –∑–∞ –ø–æ—Å–ª–µ–¥–Ω—é—é –Ω–µ–¥–µ–ª—é.

–ö—Ä–∏—Ç–µ—Ä–∏–∏ –æ—Ç–±–æ—Ä–∞:
{HR_DIGEST_CRITERIA}

–í—ã–±–µ—Ä–∏ –¥–æ 10 —Å—Ç–∞—Ç–µ–π, –∫–æ—Ç–æ—Ä—ã–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—Ç –∫—Ä–∏—Ç–µ—Ä–∏—è–º (HR-—Ç—Ä–µ–Ω–¥—ã, —Ä—ã–Ω–æ–∫ —Ç—Ä—É–¥–∞, —Ä–µ–∫—Ä—É—Ç–∏–Ω–≥, —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ª—é–¥—å–º–∏, –ò–ò –≤ HR, –∫–æ–º–º—É–Ω–∏–∫–∞—Ü–∏–∏, —Ü–µ–ª–∏, L&D –∏ —Ç.–¥.). –ù–µ –≤–∫–ª—é—á–∞–π —Å—Ç–∞—Ç—å–∏ –ø—Ä–æ ¬´–∫–∞—Ä—å–µ—Ä–∞ –≤ –º–∞—Ä–∫–µ—Ç–∏–Ω–≥–µ/—Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ¬ª –¥–ª—è –Ω–µ-HR —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç–æ–≤.
–ü–æ –∫–∞–∂–¥–æ–π –≤—ã–±—Ä–∞–Ω–Ω–æ–π —Å—Ç–∞—Ç—å–µ –Ω–∞–ø–∏—à–∏ –∫–æ—Ä–æ—Ç–∫–∏–π –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π –¥–ª—è HR (1‚Äì2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è).
–í–∞–∂–Ω–æ: –∏—Å–ø–æ–ª—å–∑—É–π –≤ –æ—Ç–≤–µ—Ç–µ —Ç–æ–ª—å–∫–æ —Ç–µ —Å—Å—ã–ª–∫–∏, —á—Ç–æ —É–∫–∞–∑–∞–Ω—ã –≤ —Å–ø–∏—Å–∫–µ (–ø–æ–ª–µ ¬´–°—Å—ã–ª–∫–∞:¬ª), –Ω–µ –ø—Ä–∏–¥—É–º—ã–≤–∞–π URL.

–í –∫–∞–∂–¥—É—é —Å—Å—ã–ª–∫—É <a href="..."> –≤—Å—Ç–∞–≤–ª—è–π —Ç–æ–ª—å–∫–æ URL –∏–∑ –ø–æ–ª—è ¬´–°—Å—ã–ª–∫–∞:¬ª –Ω–∏–∂–µ ‚Äî –∫–æ–ø–∏—Ä—É–π –µ–≥–æ –±—É–∫–≤–∞–ª—å–Ω–æ. –ó–∞–ø—Ä–µ—â–µ–Ω–æ –ø–æ–¥—Å—Ç–∞–≤–ª—è—Ç—å –ø—Ä–∏–º–µ—Ä—ã –≤—Ä–æ–¥–µ 123456-slug.

–§–æ—Ä–º–∞—Ç –≤—ã–≤–æ–¥–∞ ‚Äî –≥–æ—Ç–æ–≤—ã–π HTML –¥–ª—è Telegram, —Ç–æ–ª—å–∫–æ —ç—Ç–æ—Ç –±–ª–æ–∫ (—Å—ã—Ä–æ–π HTML, –±–µ–∑ –æ–±—ë—Ä—Ç–∫–∏ –≤ ```html –∏–ª–∏ ```):
‚Ä¢ üì∞ <b>–ó–∞–≥–æ–ª–æ–≤–æ–∫</b>
  –ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π –¥–ª—è HR: ...
  <a href="URL_–ò–ó_–ü–û–õ–Ø_–°–°–´–õ–ö–ê_–í–´–®–ï">–ò—Å—Ç–æ—á–Ω–∏–∫: vc.ru</a>

–°–ø–∏—Å–æ–∫ —Å—Ç–∞—Ç–µ–π:
---
{text_list}
---"""

    try:
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "–¢—ã HR-–¥–∏—Ä–µ–∫—Ç–æ—Ä. –û—Ç–±–∏—Ä–∞–µ—à—å —Å—Ç–∞—Ç—å–∏ –¥–ª—è –¥–∞–π–¥–∂–µ—Å—Ç–∞. –í <a href=\"...\"> –≤—Å—Ç–∞–≤–ª—è–µ—à—å —Ç–æ–ª—å–∫–æ URL –∏–∑ –ø–æ–ª—è ¬´–°—Å—ã–ª–∫–∞:¬ª —Å–ø–∏—Å–∫–∞ ‚Äî –∫–æ–ø–∏—Ä—É–µ—à—å –±—É–∫–≤–∞–ª—å–Ω–æ, –Ω–∏–∫–æ–≥–¥–∞ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—à—å –ø—Ä–∏–º–µ—Ä—ã —Ç–∏–ø–∞ 123456-slug. –§–æ—Ä–º–∞—Ç ‚Äî HTML –¥–ª—è Telegram."},
                {"role": "user", "content": prompt},
            ],
            temperature=0.2,
        )
        block = (response.choices[0].message.content or "").strip()
        if block and ("‚Ä¢ " in block or "–ò—Å—Ç–æ—á–Ω–∏–∫" in block or "vc.ru" in block):
            return block + "\n\n"
        return ""
    except Exception as e:
        print(f"vc.ru –ò–ò-–¥–∞–π–¥–∂–µ—Å—Ç –∏–∑ —Å–ø–∏—Å–∫–∞ —Å—Ç–∞—Ç–µ–π –æ—à–∏–±–∫–∞: {e}")
        return ""


def _fetch_headers():
    return {
        "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
        "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8",
        "Accept-Language": "ru-RU,ru;q=0.9,en;q=0.8",
    }


def get_page_html(url: str, timeout: int = 15) -> str:
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç —Å—Ç—Ä–∞–Ω–∏—Ü—É –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—ã—Ä–æ–π HTML (–¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞ –ø–∞—Ä –∑–∞–≥–æ–ª–æ–≤–æ–∫‚Äì—Å—Å—ã–ª–∫–∞)."""
    try:
        r = requests.get(url, headers=_fetch_headers(), timeout=timeout)
        r.raise_for_status()
        html = r.text
        return html if len(html) >= 500 else ""
    except Exception as e:
        print(f"get_page_html {url[:50]}... –æ—à–∏–±–∫–∞: {e}")
        return ""


def parse_vc_articles_from_html(html: str, max_articles: int = 25) -> list:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∏–∑ HTML vc.ru/hr –ø–∞—Ä—ã (–∑–∞–≥–æ–ª–æ–≤–æ–∫, —Å—Å—ã–ª–∫–∞), —á—Ç–æ–±—ã –∑–∞–≥–æ–ª–æ–≤–∫–∏ –∏ —Å—Å—ã–ª–∫–∏ –Ω–µ –ø—É—Ç–∞–ª–∏—Å—å."""
    try:
        from bs4 import BeautifulSoup
    except ImportError:
        return []
    articles = []
    seen = set()
    soup = BeautifulSoup(html, "html.parser")
    for a in soup.find_all("a", href=True):
        href = (a.get("href") or "").strip()
        if href.startswith("/"):
            href = "https://vc.ru" + href
        if not re.match(r"https?://vc\.ru/hr/\d", href):
            continue
        if href in seen:
            continue
        title = (a.get_text(strip=True) or "").strip()
        if not title or len(title) < 10 or len(title) > 400:
            continue
        seen.add(href)
        articles.append({"title": title[:200], "link": href, "snippet": title[:300]})
        if len(articles) >= max_articles:
            break
    return articles


def _is_habr_article_url(href: str) -> bool:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —á—Ç–æ —Å—Å—ã–ª–∫–∞ –≤–µ–¥—ë—Ç –Ω–∞ —Å—Ç–∞—Ç—å—é, –∞ –Ω–µ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—É –∫–æ–º–ø–∞–Ω–∏–∏ (habr.com/ru/company/habr_career)."""
    h = href.split("?")[0].rstrip("/")
    # –ò—Å–∫–ª—é—á–∞–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü—É –∫–æ–º–ø–∞–Ω–∏–∏ ‚Äî —Ç—É–¥–∞ –≤–µ–¥—É—Ç –æ–±—â–∏–µ —Å—Å—ã–ª–∫–∏ ¬´–•–∞–±—Ä –ö–∞—Ä—å–µ—Ä–∞¬ª
    if "habr.com/ru/company/habr_career" in h and (h.endswith("habr_career") or h.endswith("habr_career/")):
        return False
    if "habr.com/ru/company/habr_career" in h and not re.search(r"/articles/\d+", h) and not re.search(r"habr_career/\d+", h):
        return False
    # –°—Ç–∞—Ç—å—è: habr.com/ru/articles/123456 –∏–ª–∏ .../company/.../articles/123456 –∏–ª–∏ career.habr.com/.../id
    if re.search(r"/articles/\d+", h):
        return True
    if re.search(r"/p/\d+", h):
        return True
    if re.search(r"habr_career/\d+", h):
        return True
    if "career.habr.com" in h and re.search(r"/[a-z]+/\d+", h):
        return True
    return False


def parse_habr_articles_from_html(html: str, max_articles: int = 25) -> list:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∏–∑ HTML career.habr.com/journal –ø–∞—Ä—ã (–∑–∞–≥–æ–ª–æ–≤–æ–∫, —Å—Å—ã–ª–∫–∞). –¢–æ–ª—å–∫–æ —Å—Å—ã–ª–∫–∏ –Ω–∞ —Å—Ç–∞—Ç—å–∏, –Ω–µ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—É –∫–æ–º–ø–∞–Ω–∏–∏."""
    try:
        from bs4 import BeautifulSoup
    except ImportError:
        return []
    articles = []
    seen = set()
    soup = BeautifulSoup(html, "html.parser")
    for a in soup.find_all("a", href=True):
        href = (a.get("href") or "").strip()
        if not href or href in seen:
            continue
        if href.startswith("/"):
            href = "https://career.habr.com" + href
        if "career.habr.com" not in href and "habr.com" not in href:
            continue
        if not _is_habr_article_url(href):
            continue
        if href.rstrip("/").endswith("journal"):
            continue
        if len(href) < 30:
            continue
        title = (a.get_text(strip=True) or "").strip()
        if not title or len(title) < 10 or len(title) > 400:
            continue
        seen.add(href)
        articles.append({"title": title[:200], "link": href, "snippet": title[:300]})
        if len(articles) >= max_articles:
            break
    return articles


def fetch_page_via_requests(url: str, timeout: int = 15) -> str:
    """
    –ó–∞–≥—Ä—É–∑–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã —á–µ—Ä–µ–∑ requests (–±–µ–∑ Playwright).
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–µ–∫—Å—Ç —Å—Ç—Ä–∞–Ω–∏—Ü—ã: —Å—Å—ã–ª–∫–∏ –∏–∑ <a href="..."> –≤—Å—Ç–∞–≤–ª–µ–Ω—ã –≤ —Ç–µ–∫—Å—Ç, —Ç–µ–≥–∏ —É–±—Ä–∞–Ω—ã.
    """
    try:
        r = requests.get(url, headers=_fetch_headers(), timeout=timeout)
        r.raise_for_status()
        html = r.text
        if len(html) < 500:
            return ""
        text = re.sub(r'<a\s+href="(https?://[^"]+)"[^>]*>', r" \1 ", html, flags=re.I)
        text = re.sub(r"<script[^>]*>[\s\S]*?</script>", " ", text, flags=re.I)
        text = re.sub(r"<style[^>]*>[\s\S]*?</style>", " ", text, flags=re.I)
        text = re.sub(r"<[^>]+>", " ", text)
        text = re.sub(r"\s+", " ", text).strip()
        return text[:50000] if text else html[:50000]
    except Exception as e:
        print(f"fetch {url[:50]}... –æ—à–∏–±–∫–∞: {e}")
        return ""


def hr_digest_from_page_text(page_text: str, exclude_urls: set = None) -> str:
    """
    –ó–∞–ø–∞—Å–Ω–æ–π –ø—É—Ç—å: –∫–æ–≥–¥–∞ Playwright –Ω–µ –Ω–∞—à—ë–ª —Å—Ç–∞—Ç–µ–π –ø–æ —Å—Å—ã–ª–∫–∞–º, –ø–µ—Ä–µ–¥–∞—ë–º –ò–ò —Å—ã—Ä–æ–π —Ç–µ–∫—Å—Ç
    —Å—Ç—Ä–∞–Ω–∏—Ü—ã vc.ru/hr. –ò–ò –∏–∑–≤–ª–µ–∫–∞–µ—Ç –∑–∞–≥–æ–ª–æ–≤–∫–∏ —Å—Ç–∞—Ç–µ–π –∏ —Å—Å—ã–ª–∫–∏ –∏–∑ —Ç–µ–∫—Å—Ç–∞ –∏ —Ñ–æ—Ä–º–∏—Ä—É–µ—Ç –¥–∞–π–¥–∂–µ—Å—Ç.
    exclude_urls ‚Äî —É–∂–µ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–µ —Å—Å—ã–ª–∫–∏, –Ω–µ –≤–∫–ª—é—á–∞—Ç—å –≤ –¥–∞–π–¥–∂–µ—Å—Ç.
    """
    if not page_text or len(page_text.strip()) < 300:
        return ""
    exclude_hint = ""
    if exclude_urls and len(exclude_urls) > 0:
        sample = list(exclude_urls)[:15]
        exclude_hint = f"\n–ù–µ –≤–∫–ª—é—á–∞–π —Å—Ç–∞—Ç—å–∏ —Å —ç—Ç–∏–º–∏ URL (—É–∂–µ –±—ã–ª–∏ –≤ –ø—Ä–æ—à–ª–æ–º –¥–∞–π–¥–∂–µ—Å—Ç–µ): {', '.join(sample)}\n"
    prompt = f"""–ù–∏–∂–µ —Ç–µ–∫—Å—Ç –ª–µ–Ω—Ç—ã —Å vc.ru, —Ä–∞–∑–¥–µ–ª ¬´–ö–∞—Ä—å–µ—Ä–∞¬ª (HR). –í —Ç–µ–∫—Å—Ç–µ —É–∂–µ –µ—Å—Ç—å –ø–æ–ª–Ω—ã–µ URL —Å—Ç–∞—Ç–µ–π (–Ω–∞–ø—Ä–∏–º–µ—Ä https://vc.ru/hr/2713395-–Ω–∞–∑–≤–∞–Ω–∏–µ-—Å—Ç–∞—Ç—å–∏).
{exclude_hint}
–ö—Ä–∏—Ç–µ—Ä–∏–∏ –æ—Ç–±–æ—Ä–∞:
{HR_DIGEST_CRITERIA}

–ò–∑–≤–ª–µ–∫–∏ –¥–æ 10 —Å—Ç–∞—Ç–µ–π –∑–∞ –ø–æ—Å–ª–µ–¥–Ω—é—é –Ω–µ–¥–µ–ª—é (—Å–≤–µ–∂–∏–µ –≤ –Ω–∞—á–∞–ª–µ), –∫–æ—Ç–æ—Ä—ã–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—Ç –∫—Ä–∏—Ç–µ—Ä–∏—è–º. –ù–µ –≤–∫–ª—é—á–∞–π —Å—Ç–∞—Ç—å–∏ –ø—Ä–æ –∫–∞—Ä—å–µ—Ä—É –≤ –º–∞—Ä–∫–µ—Ç–∏–Ω–≥–µ/—Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ –¥–ª—è –Ω–µ-HR —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç–æ–≤.
–î–ª—è –∫–∞–∂–¥–æ–π –≤—ã–±—Ä–∞–Ω–Ω–æ–π: –∑–∞–≥–æ–ª–æ–≤–æ–∫, –∫–æ—Ä–æ—Ç–∫–∏–π HR-–∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π (1‚Äì2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è), –∏ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ —Å–∫–æ–ø–∏—Ä—É–π –≤ <a href="..."> –ø–æ–ª–Ω—ã–π URL —ç—Ç–æ–π —Å—Ç–∞—Ç—å–∏ –∏–∑ —Ç–µ–∫—Å—Ç–∞ –Ω–∏–∂–µ.

–í–∞–∂–Ω–æ: –≤ href –≤—Å—Ç–∞–≤–ª—è–π —Ç–æ–ª—å–∫–æ —Ä–µ–∞–ª—å–Ω—ã–µ —Å—Å—ã–ª–∫–∏ –∏–∑ —Ç–µ–∫—Å—Ç–∞ –ª–µ–Ω—Ç—ã ‚Äî —Å–∫–æ–ø–∏—Ä—É–π –∏—Ö –±—É–∫–≤–∞–ª—å–Ω–æ. –ó–∞–ø—Ä–µ—â–µ–Ω–æ –ø—Ä–∏–¥—É–º—ã–≤–∞—Ç—å –∏–ª–∏ –ø–æ–¥—Å—Ç–∞–≤–ª—è—Ç—å –ø—Ä–∏–º–µ—Ä—ã –≤—Ä–æ–¥–µ 123456-slug.

–§–æ—Ä–º–∞—Ç –≤—ã–≤–æ–¥–∞ ‚Äî –≥–æ—Ç–æ–≤—ã–π HTML –¥–ª—è Telegram, —Ç–æ–ª—å–∫–æ —ç—Ç–æ—Ç –±–ª–æ–∫ (—Å—ã—Ä–æ–π HTML, –±–µ–∑ –æ–±—ë—Ä—Ç–∫–∏ –≤ ```html –∏–ª–∏ ```):
‚Ä¢ –ó–∞–≥–æ–ª–æ–≤–æ–∫
  –ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π –¥–ª—è HR: ...
  <a href="–ü–û–õ–ù–´–ô_URL_–ò–ó_–¢–ï–ö–°–¢–ê_–ù–ò–ñ–ï">–ò—Å—Ç–æ—á–Ω–∏–∫: vc.ru</a>

–¢–µ–∫—Å—Ç –ª–µ–Ω—Ç—ã:
---
{page_text[:35000]}
---"""

    try:
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "–¢—ã HR-–¥–∏—Ä–µ–∫—Ç–æ—Ä. –û—Ç–±–∏—Ä–∞–µ—à—å —Å—Ç–∞—Ç—å–∏ –¥–ª—è –¥–∞–π–¥–∂–µ—Å—Ç–∞. –í –∫–∞–∂–¥—É—é —Å—Å—ã–ª–∫—É <a href=\"...\"> –≤—Å—Ç–∞–≤–ª—è–µ—à—å —Ç–æ–ª—å–∫–æ —Ä–µ–∞–ª—å–Ω—ã–π URL –∏–∑ —Ç–µ–∫—Å—Ç–∞ ‚Äî –∫–æ–ø–∏—Ä—É–µ—à—å –µ–≥–æ –∏–∑ –ª–µ–Ω—Ç—ã, –Ω–∏–∫–æ–≥–¥–∞ –Ω–µ –ø–æ–¥—Å—Ç–∞–≤–ª—è–µ—à—å –ø—Ä–∏–º–µ—Ä—ã —Ç–∏–ø–∞ 123456-slug. –§–æ—Ä–º–∞—Ç ‚Äî HTML –¥–ª—è Telegram."},
                {"role": "user", "content": prompt},
            ],
            temperature=0.2,
        )
        block = (response.choices[0].message.content or "").strip()
        # –ü—Ä–∏–Ω–∏–º–∞–µ–º –ª—é–±–æ–π –æ—Å–º—ã—Å–ª–µ–Ω–Ω—ã–π –±–ª–æ–∫ (–ò–ò –º–æ–∂–µ—Ç –≤–µ—Ä–Ω—É—Ç—å ‚Ä¢ –∏–ª–∏ - –∏–ª–∏ 1.)
        if block and len(block) > 80 and ("vc.ru" in block or "–ò—Å—Ç–æ—á–Ω–∏–∫" in block or "‚Ä¢ " in block or "http" in block):
            return block + "\n\n"
        if block and len(block) > 200:
            return block + "\n\n"
        return ""
    except Exception as e:
        print(f"vc.ru –ò–ò-–¥–∞–π–¥–∂–µ—Å—Ç –∏–∑ —Ç–µ–∫—Å—Ç–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –æ—à–∏–±–∫–∞: {e}")
        return ""


def hr_digest_from_habr_text(page_text: str, exclude_urls: set = None) -> str:
    """
    –ò–ò –∏–∑–≤–ª–µ–∫–∞–µ—Ç –∏–∑ —Ç–µ–∫—Å—Ç–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –•–∞–±—Ä –ö–∞—Ä—å–µ—Ä–∞ (career.habr.com/journal) –∑–∞–≥–æ–ª–æ–≤–∫–∏ —Å—Ç–∞—Ç–µ–π,
    —Å—Å—ã–ª–∫–∏ –∏ —Ñ–æ—Ä–º–∏—Ä—É–µ—Ç –¥–∞–π–¥–∂–µ—Å—Ç –¥–ª—è HR. exclude_urls ‚Äî —É–∂–µ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–µ —Å—Å—ã–ª–∫–∏.
    """
    if not page_text or len(page_text.strip()) < 300:
        return ""
    exclude_hint = ""
    if exclude_urls and len(exclude_urls) > 0:
        sample = list(exclude_urls)[:15]
        exclude_hint = f"\n–ù–µ –≤–∫–ª—é—á–∞–π —Å—Ç–∞—Ç—å–∏ —Å —ç—Ç–∏–º–∏ URL (—É–∂–µ –±—ã–ª–∏ –≤ –ø—Ä–æ—à–ª–æ–º –¥–∞–π–¥–∂–µ—Å—Ç–µ): {', '.join(sample)}\n"
    prompt = f"""–ù–∏–∂–µ —Ç–µ–∫—Å—Ç –ª–µ–Ω—Ç—ã —Å —Å–∞–π—Ç–∞ –•–∞–±—Ä –ö–∞—Ä—å–µ—Ä–∞ (career.habr.com/journal). –í —Ç–µ–∫—Å—Ç–µ —É–∂–µ –µ—Å—Ç—å –ø–æ–ª–Ω—ã–µ URL —Å—Ç–∞—Ç–µ–π.
{exclude_hint}
–ö—Ä–∏—Ç–µ—Ä–∏–∏ –æ—Ç–±–æ—Ä–∞:
{HR_DIGEST_CRITERIA}

–ò–∑–≤–ª–µ–∫–∏ –¥–æ 8 —Å—Ç–∞—Ç–µ–π –∑–∞ –ø–æ—Å–ª–µ–¥–Ω—é—é –Ω–µ–¥–µ–ª—é (—Å–≤–µ–∂–∏–µ –≤ –Ω–∞—á–∞–ª–µ), –∫–æ—Ç–æ—Ä—ã–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—Ç –∫—Ä–∏—Ç–µ—Ä–∏—è–º. –ù–µ –≤–∫–ª—é—á–∞–π —Å—Ç–∞—Ç—å–∏ –ø—Ä–æ ¬´–∫–∞—Ä—å–µ—Ä–∞ –≤ –º–∞—Ä–∫–µ—Ç–∏–Ω–≥–µ¬ª, ¬´–∫–∞–∫ —Å—Ç–∞—Ç—å —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–æ–º¬ª –∏ —Ç.–ø. ‚Äî —Ç–æ–ª—å–∫–æ —Ç–æ, —á—Ç–æ –ø–æ–ª–µ–∑–Ω–æ HR-—Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç—É.
–î–ª—è –∫–∞–∂–¥–æ–π –≤—ã–±—Ä–∞–Ω–Ω–æ–π: –∑–∞–≥–æ–ª–æ–≤–æ–∫, –∫–æ—Ä–æ—Ç–∫–∏–π HR-–∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π (1‚Äì2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è), –∏ —Å–∫–æ–ø–∏—Ä—É–π –≤ <a href="..."> –ø–æ–ª–Ω—ã–π URL —ç—Ç–æ–π —Å—Ç–∞—Ç—å–∏ –∏–∑ —Ç–µ–∫—Å—Ç–∞ –Ω–∏–∂–µ.

–í–∞–∂–Ω–æ: –≤ href –≤—Å—Ç–∞–≤–ª—è–π —Ç–æ–ª—å–∫–æ —Ä–µ–∞–ª—å–Ω—ã–µ —Å—Å—ã–ª–∫–∏ –∏–∑ —Ç–µ–∫—Å—Ç–∞ ‚Äî –∫–æ–ø–∏—Ä—É–π –∏—Ö –±—É–∫–≤–∞–ª—å–Ω–æ. –ó–∞–ø—Ä–µ—â–µ–Ω–æ –ø—Ä–∏–¥—É–º—ã–≤–∞—Ç—å URL.

–§–æ—Ä–º–∞—Ç –≤—ã–≤–æ–¥–∞ ‚Äî –≥–æ—Ç–æ–≤—ã–π HTML –¥–ª—è Telegram, —Ç–æ–ª—å–∫–æ —ç—Ç–æ—Ç –±–ª–æ–∫ (—Å—ã—Ä–æ–π HTML, –±–µ–∑ –æ–±—ë—Ä—Ç–∫–∏ –≤ ```html –∏–ª–∏ ```):
‚Ä¢ –ó–∞–≥–æ–ª–æ–≤–æ–∫
  –ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π –¥–ª—è HR: ...
  <a href="–ü–û–õ–ù–´–ô_URL_–ò–ó_–¢–ï–ö–°–¢–ê_–ù–ò–ñ–ï">–ò—Å—Ç–æ—á–Ω–∏–∫: –•–∞–±—Ä –ö–∞—Ä—å–µ—Ä–∞</a>

–¢–µ–∫—Å—Ç –ª–µ–Ω—Ç—ã:
---
{page_text[:35000]}
---"""

    try:
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "–¢—ã HR-–¥–∏—Ä–µ–∫—Ç–æ—Ä. –û—Ç–±–∏—Ä–∞–µ—à—å —Å—Ç–∞—Ç—å–∏ –¥–ª—è –¥–∞–π–¥–∂–µ—Å—Ç–∞. –í –∫–∞–∂–¥—É—é —Å—Å—ã–ª–∫—É <a href=\"...\"> –≤—Å—Ç–∞–≤–ª—è–µ—à—å —Ç–æ–ª—å–∫–æ —Ä–µ–∞–ª—å–Ω—ã–π URL –∏–∑ —Ç–µ–∫—Å—Ç–∞ –ª–µ–Ω—Ç—ã ‚Äî –∫–æ–ø–∏—Ä—É–µ—à—å –µ–≥–æ, –Ω–∏–∫–æ–≥–¥–∞ –Ω–µ –ø—Ä–∏–¥—É–º—ã–≤–∞–µ—à—å. –§–æ—Ä–º–∞—Ç ‚Äî HTML –¥–ª—è Telegram."},
                {"role": "user", "content": prompt},
            ],
            temperature=0.2,
        )
        block = (response.choices[0].message.content or "").strip()
        if block and len(block) > 80 and ("career.habr" in block or "–ò—Å—Ç–æ—á–Ω–∏–∫" in block or "‚Ä¢ " in block or "http" in block):
            return block + "\n\n"
        if block and len(block) > 200:
            return block + "\n\n"
        return ""
    except Exception as e:
        print(f"–•–∞–±—Ä –ö–∞—Ä—å–µ—Ä–∞ –ò–ò-–¥–∞–π–¥–∂–µ—Å—Ç –æ—à–∏–±–∫–∞: {e}")
        return ""


def hr_digest_from_habr_articles(articles: list) -> str:
    """
    –ò–ò –ø–æ–ª—É—á–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —Å—Ç–∞—Ç–µ–π –•–∞–±—Ä –ö–∞—Ä—å–µ—Ä–∞ (–∑–∞–≥–æ–ª–æ–≤–æ–∫ + —Å—Å—ã–ª–∫–∞ —É–∂–µ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω—ã).
    –í—ã–±–∏—Ä–∞–µ—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –¥–ª—è HR, –ø–∏—à–µ—Ç –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π –ø–æ –∫–∞–∂–¥–æ–π. –°—Å—ã–ª–∫–∏ –Ω–µ –ø—É—Ç–∞—é—Ç—Å—è —Å –∑–∞–≥–æ–ª–æ–≤–∫–∞–º–∏.
    """
    if not articles:
        return ""
    lines = []
    for i, a in enumerate(articles[:25], 1):
        title = (a.get("title") or "").strip()
        link = (a.get("link") or "").strip()
        snippet = (a.get("snippet") or title or "")[:500]
        if not title or not link:
            continue
        lines.append(f"{i}. {title}\n   –°—Å—ã–ª–∫–∞: {link}\n   –¢–µ–∫—Å—Ç: {snippet}")
    text_list = "\n\n".join(lines)
    if not text_list:
        return ""

    prompt = f"""–ù–∏–∂–µ —Å–ø–∏—Å–æ–∫ —Å—Ç–∞—Ç–µ–π —Å –•–∞–±—Ä –ö–∞—Ä—å–µ—Ä–∞ (career.habr.com/journal). –£ –∫–∞–∂–¥–æ–π —Å—Ç–∞—Ç—å–∏ –∑–∞–≥–æ–ª–æ–≤–æ–∫ –∏ —Å—Å—ã–ª–∫–∞ —É–∂–µ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω—ã.

–ö—Ä–∏—Ç–µ—Ä–∏–∏ –æ—Ç–±–æ—Ä–∞:
{HR_DIGEST_CRITERIA}

–í—ã–±–µ—Ä–∏ –¥–æ 8 —Å—Ç–∞—Ç–µ–π, —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –¥–ª—è HR (—Ç—Ä–µ–Ω–¥—ã, —Ä—ã–Ω–æ–∫ —Ç—Ä—É–¥–∞, —Ä–µ–∫—Ä—É—Ç–∏–Ω–≥, –ò–ò –≤ HR, –∫–æ–º–º—É–Ω–∏–∫–∞—Ü–∏–∏, —Ü–µ–ª–∏, L&D). –ù–µ –≤–∫–ª—é—á–∞–π –∫–∞—Ä—å–µ—Ä–Ω—ã–µ –≥–∞–π–¥—ã –¥–ª—è –Ω–µ-HR —Ä–æ–ª–µ–π.
–ü–æ –∫–∞–∂–¥–æ–π –≤—ã–±—Ä–∞–Ω–Ω–æ–π –Ω–∞–ø–∏—à–∏ –∫–æ—Ä–æ—Ç–∫–∏–π HR-–∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π (1‚Äì2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è).
–í –∫–∞–∂–¥—É—é —Å—Å—ã–ª–∫—É <a href="..."> –≤—Å—Ç–∞–≤–ª—è–π —Ç–æ–ª—å–∫–æ URL –∏–∑ –ø–æ–ª—è ¬´–°—Å—ã–ª–∫–∞:¬ª ‚Äî –∫–æ–ø–∏—Ä—É–π –±—É–∫–≤–∞–ª—å–Ω–æ, –∑–∞–≥–æ–ª–æ–≤–æ–∫ –∏ —Å—Å—ã–ª–∫–∞ –¥–æ–ª–∂–Ω—ã —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–æ–≤–∞—Ç—å –æ–¥–Ω–æ–π –∏ —Ç–æ–π –∂–µ —Å—Ç—Ä–æ–∫–µ —Å–ø–∏—Å–∫–∞.

–§–æ—Ä–º–∞—Ç –≤—ã–≤–æ–¥–∞ ‚Äî –≥–æ—Ç–æ–≤—ã–π HTML –¥–ª—è Telegram (—Å—ã—Ä–æ–π HTML, –±–µ–∑ ```html):
‚Ä¢ –ó–∞–≥–æ–ª–æ–≤–æ–∫ (—Ç–æ—á–Ω–æ –∏–∑ —Å–ø–∏—Å–∫–∞)
  –ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π –¥–ª—è HR: ...
  <a href="URL_–ò–ó_–ü–û–õ–Ø_–°–°–´–õ–ö–ê_–≠–¢–û–ô_–°–¢–†–û–ö–ò">–ò—Å—Ç–æ—á–Ω–∏–∫: –•–∞–±—Ä –ö–∞—Ä—å–µ—Ä–∞</a>

–°–ø–∏—Å–æ–∫ —Å—Ç–∞—Ç–µ–π:
---
{text_list}
---"""

    try:
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "–¢—ã HR-–¥–∏—Ä–µ–∫—Ç–æ—Ä. –î–ª—è –∫–∞–∂–¥–æ–π —Å—Ç–∞—Ç—å–∏ –∏–∑ —Å–ø–∏—Å–∫–∞ –∏—Å–ø–æ–ª—å–∑—É–π —Ä–æ–≤–Ω–æ —Ç—É —Å—Å—ã–ª–∫—É, —á—Ç–æ —É–∫–∞–∑–∞–Ω–∞ –≤ –ø–æ–ª–µ ¬´–°—Å—ã–ª–∫–∞:¬ª —ç—Ç–æ–π –∂–µ —Å—Ç—Ä–æ–∫–∏. –ó–∞–≥–æ–ª–æ–≤–æ–∫ –∏ —Å—Å—ã–ª–∫–∞ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –∏–∑ –æ–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏ —Å–ø–∏—Å–∫–∞. –§–æ—Ä–º–∞—Ç ‚Äî HTML –¥–ª—è Telegram."},
                {"role": "user", "content": prompt},
            ],
            temperature=0.2,
        )
        block = (response.choices[0].message.content or "").strip()
        if block and ("‚Ä¢ " in block or "–ò—Å—Ç–æ—á–Ω–∏–∫" in block or "habr" in block):
            return block + "\n\n"
        return ""
    except Exception as e:
        print(f"–•–∞–±—Ä –ö–∞—Ä—å–µ—Ä–∞ –ò–ò-–¥–∞–π–¥–∂–µ—Å—Ç –∏–∑ —Å–ø–∏—Å–∫–∞ –æ—à–∏–±–∫–∞: {e}")
        return ""


def collect_habr_news(used_titles, sent_articles=None):
    """
    –ù–æ–≤–æ—Å—Ç–∏ —Å –•–∞–±—Ä –ö–∞—Ä—å–µ—Ä–∞: –ø–∞—Ä—Å–∏–º HTML ‚Üí –ø–∞—Ä—ã (–∑–∞–≥–æ–ª–æ–≤–æ–∫, —Å—Å—ã–ª–∫–∞) ‚Üí –ò–ò –¥–æ–±–∞–≤–ª—è–µ—Ç –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏.
    –¢–∞–∫ –∑–∞–≥–æ–ª–æ–≤–∫–∏ –∏ —Å—Å—ã–ª–∫–∏ –Ω–µ –ø—É—Ç–∞—é—Ç—Å—è.
    """
    sent_articles = sent_articles or set()
    print("–•–∞–±—Ä –ö–∞—Ä—å–µ—Ä–∞: –∑–∞–≥—Ä—É–∑–∫–∞ HTML...")
    html = get_page_html(HABR_JOURNAL_URL)
    if not html:
        return "", used_titles
    articles = parse_habr_articles_from_html(html)
    articles = [a for a in articles if a.get("link") not in sent_articles]
    print("–•–∞–±—Ä –ö–∞—Ä—å–µ—Ä–∞: –∏–∑–≤–ª–µ—á–µ–Ω–æ —Å—Ç–∞—Ç–µ–π (–∑–∞–≥–æ–ª–æ–≤–æ–∫+—Å—Å—ã–ª–∫–∞):", len(articles))
    if articles:
        print("–•–∞–±—Ä –ö–∞—Ä—å–µ—Ä–∞: –ò–ò —Ñ–æ—Ä–º–∏—Ä—É–µ—Ç –¥–∞–π–¥–∂–µ—Å—Ç –∏–∑ —Å–ø–∏—Å–∫–∞...")
        block = hr_digest_from_habr_articles(articles)
        if block:
            print("–•–∞–±—Ä –ö–∞—Ä—å–µ—Ä–∞: –¥–∞–π–¥–∂–µ—Å—Ç –≥–æ—Ç–æ–≤")
            return block, used_titles
    print("–•–∞–±—Ä –ö–∞—Ä—å–µ—Ä–∞: –ø–∞—Ä—Å–∏–Ω–≥ –Ω–µ –¥–∞–ª —Å—Ç–∞—Ç–µ–π, –ø—Ä–æ–±—É–µ–º –ø–æ —Ç–µ–∫—Å—Ç—É...")
    page_text = fetch_page_via_requests(HABR_JOURNAL_URL)
    if page_text and len(page_text.strip()) >= 500:
        block = hr_digest_from_habr_text(page_text, exclude_urls=sent_articles)
        if block:
            return block, used_titles
    return "", used_titles


def collect_vc_news(used_titles, sent_articles=None):
    """
    –ù–æ–≤–æ—Å—Ç–∏ —Å vc.ru: —Å–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º requests (–±–µ–∑ Playwright), –ø–æ—Ç–æ–º Playwright.
    –ò–ò —Ñ–æ—Ä–º–∏—Ä—É–µ—Ç –¥–∞–π–¥–∂–µ—Å—Ç –∑–∞ –Ω–µ–¥–µ–ª—é –ø–æ HR-—Ç–µ–º–∞—Ç–∏–∫–µ. sent_articles ‚Äî —É–∂–µ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–µ URL, –Ω–µ –ø–æ–≤—Ç–æ—Ä—è—Ç—å.
    """
    sent_articles = sent_articles or set()
    # 1) –ü–∞—Ä—Å–∏–º HTML ‚Üí –ø–∞—Ä—ã (–∑–∞–≥–æ–ª–æ–≤–æ–∫, —Å—Å—ã–ª–∫–∞), —á—Ç–æ–±—ã –∑–∞–≥–æ–ª–æ–≤–∫–∏ –∏ —Å—Å—ã–ª–∫–∏ –Ω–µ –ø—É—Ç–∞–ª–∏—Å—å
    print("vc.ru: –∑–∞–≥—Ä—É–∑–∫–∞ HTML...")
    html = get_page_html(VC_CHANNEL_URL)
    if html:
        articles = parse_vc_articles_from_html(html)
        articles = [a for a in articles if a.get("link") not in sent_articles]
        print("vc.ru: –∏–∑–≤–ª–µ—á–µ–Ω–æ —Å—Ç–∞—Ç–µ–π (–∑–∞–≥–æ–ª–æ–≤–æ–∫+—Å—Å—ã–ª–∫–∞):", len(articles))
        if articles:
            print("vc.ru: –ò–ò —Ñ–æ—Ä–º–∏—Ä—É–µ—Ç –¥–∞–π–¥–∂–µ—Å—Ç –∏–∑ —Å–ø–∏—Å–∫–∞...")
            block = hr_digest_from_vc_articles(articles)
            if block:
                print("vc.ru: –¥–∞–π–¥–∂–µ—Å—Ç –≥–æ—Ç–æ–≤ (–ø–∞—Ä—Å–∏–Ω–≥ HTML)")
                return block, used_titles
    print("vc.ru: –ø–∞—Ä—Å–∏–Ω–≥ –Ω–µ –¥–∞–ª —Å—Ç–∞—Ç–µ–π, –ø—Ä–æ–±—É–µ–º –ø–æ —Ç–µ–∫—Å—Ç—É...")
    page_text = fetch_page_via_requests(VC_CHANNEL_URL)
    if page_text and len(page_text.strip()) >= 500:
        block = hr_digest_from_page_text(page_text, exclude_urls=sent_articles)
        if block:
            print("vc.ru: –¥–∞–π–¥–∂–µ—Å—Ç –≥–æ—Ç–æ–≤ (—Ç–µ–∫—Å—Ç)")
            return block, used_titles
    print("vc.ru: –ø—Ä–æ–±—É–µ–º Playwright...")

    try:
        from vc_discovery import collect_vc_channel, collect_vc_discovery, get_vc_page_text
    except ImportError:
        print("vc.ru: –º–æ–¥—É–ª—å vc_discovery –Ω–µ –Ω–∞–π–¥–µ–Ω (Playwright –Ω–µ –æ–±—è–∑–∞—Ç–µ–ª–µ–Ω)")
        return "", used_titles

    print("vc.ru: –∑–∞–≥—Ä—É–∑–∫–∞ –ª–µ–Ω—Ç—ã vc.ru/hr —á–µ—Ä–µ–∑ Playwright...")
    articles_channel = collect_vc_channel(
        channel_url=VC_CHANNEL_URL,
        max_articles=VC_CHANNEL_MAX,
    )
    print("vc.ru: –∑–∞–≥—Ä—É–∑–∫–∞ discovery –ø–æ HR...")
    articles_discovery = collect_vc_discovery(
        query=VC_DISCOVERY_QUERY,
        max_articles=VC_DISCOVERY_MAX,
    )
    # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º —Å—Å—ã–ª–∫–∏ api.vc.ru/redirect?to=... –≤ —Ä–µ–∞–ª—å–Ω—ã–µ URL
    def _norm(a_list):
        return [{"title": x.get("title", ""), "link": _normalize_vc_redirect_link((x.get("link") or "").strip()), "snippet": x.get("snippet", x.get("title", ""))} for x in a_list]
    articles_channel = _norm(articles_channel)
    articles_discovery = _norm(articles_discovery)
    # –û–±—ä–µ–¥–∏–Ω—è–µ–º, —É–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏ –ø–æ —Å—Å—ã–ª–∫–µ (channel –ø–µ—Ä–≤—ã–º–∏ ‚Äî —Ç–∞–º —Å–≤–µ–∂–µ–µ)
    seen_links = set()
    merged = []
    for a in articles_channel + articles_discovery:
        link = (a.get("link") or "").strip()
        if link and link not in seen_links and (not sent_articles or link not in sent_articles):
            seen_links.add(link)
            merged.append(a)
    print("vc.ru: –≤—Å–µ–≥–æ —Å—Ç–∞—Ç–µ–π –¥–ª—è –ò–ò (–±–µ–∑ —É–∂–µ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã—Ö):", len(merged))

    block = ""
    if merged:
        print("vc.ru: –ò–ò —Ñ–æ—Ä–º–∏—Ä—É–µ—Ç –¥–∞–π–¥–∂–µ—Å—Ç –∑–∞ –Ω–µ–¥–µ–ª—é –ø–æ HR...")
        block = hr_digest_from_vc_articles(merged)
        if block:
            print("vc.ru: –¥–∞–π–¥–∂–µ—Å—Ç –≥–æ—Ç–æ–≤, —Å–∏–º–≤–æ–ª–æ–≤:", len(block))
            return block, used_titles
        print("vc.ru: –ò–ò –≤–µ—Ä–Ω—É–ª –ø—É—Å—Ç–æ–π –±–ª–æ–∫, –ø—Ä–æ–±—É–µ–º –¥–∞–π–¥–∂–µ—Å—Ç –∏–∑ —Ç–µ–∫—Å—Ç–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã (Playwright)...")

    # –ó–∞–ø–∞—Å–Ω–æ–π –ø—É—Ç—å: –¥–∞–π–¥–∂–µ—Å—Ç –∏–∑ —Ç–µ–∫—Å—Ç–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã (–∫–æ–≥–¥–∞ —Å–ø–∏—Å–∫–∞ —Å—Ç–∞—Ç–µ–π –Ω–µ—Ç –∏–ª–∏ –ò–ò –≤–µ—Ä–Ω—É–ª –ø—É—Å—Ç–æ)
    page_text = None
    if not merged or not block:
        print("vc.ru: –∑–∞–≥—Ä—É–∂–∞–µ–º —Ç–µ–∫—Å—Ç —Å—Ç—Ä–∞–Ω–∏—Ü—ã –¥–ª—è –ò–ò...")
        page_text = get_vc_page_text(url=VC_CHANNEL_URL, scroll_times=4)
        print("vc.ru: –ø–æ–ª—É—á–µ–Ω–æ —Å–∏–º–≤–æ–ª–æ–≤:", len(page_text or ""))
    if page_text and len(page_text.strip()) >= 300:
        block = hr_digest_from_page_text(page_text, exclude_urls=sent_articles)
        if block:
            print("vc.ru: –¥–∞–π–¥–∂–µ—Å—Ç –∏–∑ —Ç–µ–∫—Å—Ç–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –≥–æ—Ç–æ–≤")
            return block, used_titles

    # –ü–æ—Å–ª–µ–¥–Ω–∏–π –≤–∞—Ä–∏–∞–Ω—Ç: –ø–æ –∫–∞–∂–¥–æ–π —Å—Ç–∞—Ç—å–µ –≤—ã–∑—ã–≤–∞–µ–º –ò–ò (—Ç–æ–ª—å–∫–æ —Å –Ω–æ—Ä–º–∞–ª—å–Ω—ã–º–∏ –∑–∞–≥–æ–ª–æ–≤–∫–∞–º–∏)
    block = ""
    b1, used_titles, n1 = _add_vc_articles_to_block(
        articles_channel, used_titles, VC_CHANNEL_MAX, source_label="vc.ru/hr"
    )
    block += b1
    b2, used_titles, n2 = _add_vc_articles_to_block(
        articles_discovery, used_titles, VC_DISCOVERY_MAX, source_label="vc.ru"
    )
    block += b2
    if n1 or n2:
        print("vc.ru: –≤ –¥–∞–π–¥–∂–µ—Å—Ç –¥–æ–±–∞–≤–ª–µ–Ω–æ –ø–æ –æ–¥–Ω–æ–π —Å—Ç–∞—Ç—å–µ:", n1 + n2)
    return block, used_titles


async def collect_telegram_news(used_titles):
    """–°–±–æ—Ä –Ω–æ–≤–æ—Å—Ç–µ–π –∏–∑ Telegram. –ü–æ–∫–∞ –∑–∞–≥–ª—É—à–∫–∞ ‚Äî –∫–∞–Ω–∞–ª—ã –Ω–µ –ø–æ–¥–∫–ª—é—á–µ–Ω—ã."""
    print("Telegram –ø–æ–∫–∞ –Ω–µ –ø–æ–¥–∫–ª—é—á—ë–Ω")
    return ""


def run_digest(sent_articles=None):
    """–°–æ–±–∏—Ä–∞–µ—Ç –¥–∞–π–¥–∂–µ—Å—Ç –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–µ–∫—Å—Ç —Å–æ–æ–±—â–µ–Ω–∏—è. sent_articles ‚Äî –º–Ω–æ–∂–µ—Å—Ç–≤–æ —É–∂–µ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã—Ö URL."""
    sent_articles = sent_articles or set()
    today = datetime.now().strftime("%d %B %Y")
    used_titles = set()

    print("–°–±–æ—Ä –Ω–æ–≤–æ—Å—Ç–µ–π —Å vc.ru (–ö–∞—Ä—å–µ—Ä–∞ + discovery)...")
    vc_block, used_titles = collect_vc_news(used_titles, sent_articles)
    vc_block = clean_digest_block(vc_block)

    print("–°–±–æ—Ä –Ω–æ–≤–æ—Å—Ç–µ–π —Å –•–∞–±—Ä –ö–∞—Ä—å–µ—Ä–∞ (journal)...")
    habr_block, used_titles = collect_habr_news(used_titles, sent_articles)
    habr_block = clean_digest_block(habr_block)

    print("–°–±–æ—Ä Telegram –Ω–æ–≤–æ—Å—Ç–µ–π...")
    tg_block = asyncio.run(collect_telegram_news(used_titles))

    digest_blocks = [b.strip() for b in (vc_block, habr_block, tg_block) if b and b.strip()]
    body = "\n\n".join(digest_blocks)
    result_text = (
        f"üì¨ <b>HR-–¥–∞–π–¥–∂–µ—Å—Ç ¬∑ {today}</b>\n\n"
        f"üß† <b>–ö–ª—é—á–µ–≤—ã–µ —Å–∏–≥–Ω–∞–ª—ã –Ω–µ–¥–µ–ª–∏</b>\n\n"
        f"{body}"
    )
    if not (vc_block.strip() or habr_block.strip() or tg_block.strip()):
        result_text += "–ó–∞ —ç—Ç—É –Ω–µ–¥–µ–ª—é –Ω–æ–≤–æ—Å—Ç–µ–π –Ω–µ –Ω–∞–π–¥–µ–Ω–æ. –ü—Ä–æ–≤–µ—Ä—å vc.ru, –•–∞–±—Ä –ö–∞—Ä—å–µ—Ä–∞ –∏ –∏—Å—Ç–æ—á–Ω–∏–∫–∏.\n"
    return result_text


def send_digest(chat_id=None):
    """–°–æ–±–∏—Ä–∞–µ—Ç –¥–∞–π–¥–∂–µ—Å—Ç, –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –≤ Telegram –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç —Å—Å—ã–ª–∫–∏, —á—Ç–æ–±—ã –Ω–æ–≤–æ—Å—Ç–∏ –Ω–µ –ø–æ–≤—Ç–æ—Ä—è–ª–∏—Å—å."""
    try:
        sent_articles = load_sent_articles()
        print("–£–∂–µ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ —Å—Å—ã–ª–æ–∫:", len(sent_articles))
        result_text = run_digest(sent_articles)
        send_to_telegram(result_text, chat_id=chat_id)
        new_links = extract_article_links(result_text)
        if new_links:
            save_sent_articles(new_links)
        print("–ì–û–¢–û–í–û ‚úÖ")
    except Exception as e:
        print("–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–ø—Ä–∞–≤–∫–µ –¥–∞–π–¥–∂–µ—Å—Ç–∞:", e)
        import traceback
        traceback.print_exc()


def bot_polling_loop():
    """–°–ª—É—à–∞–µ—Ç –∫–æ–º–∞–Ω–¥—ã –≤ Telegram: /digest –∏–ª–∏ /–¥–∞–π–¥–∂–µ—Å—Ç ‚Äî –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –¥–∞–π–¥–∂–µ—Å—Ç."""
    url = f"https://api.telegram.org/bot{TELEGRAM_TOKEN}/getUpdates"
    offset = None
    while True:
        try:
            params = {"timeout": 30}
            if offset is not None:
                params["offset"] = offset
            r = requests.get(url, params=params, timeout=35)
            data = r.json()
            if not data.get("ok"):
                time.sleep(5)
                continue
            for upd in data.get("result", []):
                offset = upd["update_id"] + 1
                msg = upd.get("message") or upd.get("edited_message")
                if not msg:
                    continue
                text = (msg.get("text") or "").strip()
                chat_id = str(msg.get("chat", {}).get("id"))
                if text.lower().startswith("/digest") or text.strip().lower() == "/–¥–∞–π–¥–∂–µ—Å—Ç":
                    print("–ö–æ–º–∞–Ω–¥–∞ /digest –æ—Ç chat_id:", chat_id)
                    send_to_telegram("–°–æ–±–∏—Ä–∞—é –¥–∞–π–¥–∂–µ—Å—Ç‚Ä¶", chat_id=chat_id)
                    send_digest(chat_id=chat_id)
                    send_to_telegram("–î–∞–π–¥–∂–µ—Å—Ç –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω.", chat_id=chat_id)
        except Exception as e:
            print("Bot polling –æ—à–∏–±–∫–∞:", e)
            time.sleep(10)


def scheduler_loop():
    """–ó–∞–ø—É—Å–∫–∞–µ—Ç –¥–∞–π–¥–∂–µ—Å—Ç –ø–æ –ø–æ–Ω–µ–¥–µ–ª—å–Ω–∏–∫–∞–º –∏ —á–µ—Ç–≤–µ—Ä–≥–∞–º –≤ DIGEST_TIME."""
    try:
        import schedule
    except ImportError:
        print("–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ schedule: pip install schedule")
        return
    schedule.every().monday.at(DIGEST_TIME).do(send_digest)
    schedule.every().thursday.at(DIGEST_TIME).do(send_digest)
    print("–†–∞—Å–ø–∏—Å–∞–Ω–∏–µ: –ø–æ–Ω–µ–¥–µ–ª—å–Ω–∏–∫ –∏ —á–µ—Ç–≤–µ—Ä–≥ –≤", DIGEST_TIME)
    while True:
        schedule.run_pending()
        time.sleep(60)


if __name__ == "__main__":
    import sys
    if len(sys.argv) > 1 and sys.argv[1] == "--once":
        # –û–¥–∏–Ω —Ä–∞–∑ –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –¥–∞–π–¥–∂–µ—Å—Ç –∏ –≤—ã–π—Ç–∏ (—É–¥–æ–±–Ω–æ –¥–ª—è —Ä—É—á–Ω–æ–≥–æ –∑–∞–ø—É—Å–∫–∞ –∏–ª–∏ cron)
        print("–†–µ–∂–∏–º: –æ–¥–∏–Ω –∑–∞–ø—É—Å–∫ –¥–∞–π–¥–∂–µ—Å—Ç–∞")
        send_digest()
        sys.exit(0)

    # –†–µ–∂–∏–º –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: –±–æ—Ç —Å–ª—É—à–∞–µ—Ç –∫–æ–º–∞–Ω–¥—ã + —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ –ø–æ–Ω–µ–¥–µ–ª—å–Ω–∏–∫/—á–µ—Ç–≤–µ—Ä–≥
    print("–ó–∞–ø—É—Å–∫: –±–æ—Ç (–∫–æ–º–∞–Ω–¥–∞ /digest) + —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ –ø–Ω/—á—Ç", DIGEST_TIME)
    thread_bot = threading.Thread(target=bot_polling_loop, daemon=True)
    thread_bot.start()
    scheduler_loop()
